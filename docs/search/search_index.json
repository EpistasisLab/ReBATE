{
    "docs": [
        {
            "location": "/",
            "text": "ReBATE\n includes stand-alone Python code to run any of the included/available \nRelief-Based algorithms (RBAs)\n \ndesigned for feature weighting/selection as part of a machine learning pipeline (supervised learning). Presently this includes the following core RBAs: ReliefF, SURF, SURF*, MultiSURF*, and MultiSURF. Additionally, an implementation of the iterative TuRF mechanism is included. As of 5/7/18, \nit is still under active development\n and we encourage you to check back on this repository regularly for updates.\n\n\nThese algorithms offer a computationally efficient way to perform feature selection that is sensitive to feature interactions as well as simple univariate associations, unlike most currently available filter-based feature selection methods. The main benefit of Relief algorithms is that they identify feature interactions without having to exhaustively check every pairwise interaction, thus taking significantly less time than exhaustive pairwise search.\n\n\nEach core algorithm outputs an ordered set of feature names along with respective feature scores (i.e. weights). Certain algorithms require user specified run parameters (e.g. ReliefF requires the user to specify some 'k' number of nearest neighbors). \n\n\nRelief algorithms are commonly applied to genetic analyses, where epistasis (i.e., feature interactions) is common. However, the algorithms implemented in this package can be applied to almost any supervised classification data set and supports:\n\n\n\n\n\n\nFeature sets that are discrete/categorical, continuous-valued or a mix of both\n\n\n\n\n\n\nData with missing values\n\n\n\n\n\n\nBinary endpoints (i.e., classification)\n\n\n\n\n\n\nMulti-class endpoints (i.e., classification)\n\n\n\n\n\n\nContinuous endpoints (i.e., regression)\n\n\n\n\n\n\nBuilt into this code, is a strategy to 'automatically' detect from the loaded data, these relevant characteristics.\n\n\nOf our two initial ReBATE software releases, this stand-alone version primarily focuses on improving run-time with the use of Cython. \nThis code is most appropriate for more experienced users or those primarily interested in reducing analysis run time. \n\n\nWe recommend that scikit-learn users, Windows operating system users, beginners, or those looking for the most recent ReBATE developments to instead use our alternate \nscikit-rebate\n implementation. ReBATE can be run on Windows with some additional installation steps and possible troubleshooting outlined below.",
            "title": "Home"
        },
        {
            "location": "/installing/",
            "text": "Installing ReBATE\n\n\nHere we describe how ReBATE can be used by downloading the source from GitHub. At a later date, we are aiming to make ReBATE available for easy installation as a pip install python package. \n\n\nPrerequisites\n\n\nAll of the necessary Python packages can be installed via the \nAnaconda Python distribution\n, which we strongly recommend that you use. We also strongly recommend that you use Python 3 over Python 2 if you're given the choice.\n\n\nReBATE requires that the following external Python packages be installed (all included in Anaconda):\n\n\nargparse, time, sys, os, IO, Common, numpy, math, pandas, scipy.spatial.distance, operator, csv, distutils.core, distutils.extension, Cython.Distutils, datetime\n\n\nNumPy and SciPy can be installed in Anaconda via the command:\n\n\nconda install numpy scipy\n\n\n\n\nAdditional Steps For Windows Users\n\n\nHere we discuss the additional prerequisites for running ReBATE on a Windows operating system. First you will need a command line terminal for Windows (e.g. \nCygwin\n, or \nGitBash\n) with Anaconda properly installed. From this terminal you can compile the Cython code, and run ReBATE. Second you will need a C compiler for compiling the Cython code once before being able to run ReBATE on your Windows machine. \n\n\nThere are a number of possible ways to get the C compiler working on your Windows terminal, all of which will depend on the version of windows, the version of python/Anaconda, and whether it is 32-bit or 64-bit. Be aware that there may be some troubleshooting in getting the C compiler operational in your command line terminal. Below we outline steps that worked for us in the spring of 2018 using Windows 10, and Python 3.5.2 with Anaconda 4.0 (64-bit), using GitBash as our terminal.\n\n\n1.) Ensure that setuptools is updated. Run the following in your terminal: \n\n\npip install -upgrade setuptools\n\n\n\n\n2.) \nDownload/install Visual Studio Community 2017\n. This includes the necessary C compiler. It is not necessary to install all of the visual studio components, as this can be slow and take up a good deal of space. However make sure that you download and install the 'Desktop Development with C++' and the 'Python Development' workloads as detailed at the following \nlink\n.  Within the Python Development workload, also select the box on the right for Python native development tools. \n\n\n3.) Once Visual Studio has been successfully installed, there was a remaining bug that required some troubleshooting for the C compiler to be found by the terminal. Try compiling Cython as described below and if it doesn't work try something like the following fix that worked for us: \n\n\n(A) \nAdd this to your PATH environment variables\n: C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64   \n\n\n(B) Copy these two files (rc.exe and rcdll.dll) from (C:\\Program Files (x86)\\Windows Kits\\8.1\\bin\\x86) to (C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin)\n\n\n4.) At this point you should be able to compile Cython as described below.\n\n\nCompile Cython\n\n\nOnce these prerequisites are installed, it will be necessary to compile the Cython code on the respective operating system within which ReBATE will be run. It is only necessary to do this once, not every time ReBATE is run. This happens in two stages (1) a .pyx file is compiled by cython to a .c file, then (2) the .c file is compiled by a C compiler to a .so file (or a .pyd file for Windows). \n\n\nFrom the root directory simply run the following file included with ReBATE to produce the .c and (.so or .pyd) files:  \n\n\n./make.sh\n\n\n\n\nIf there is need to recompile the Cython files, first remove the previous .c and (.so or .pyd) files run the following from the root directory: \n\n\n./clean.sh",
            "title": "Installation"
        },
        {
            "location": "/installing/#installing-rebate",
            "text": "Here we describe how ReBATE can be used by downloading the source from GitHub. At a later date, we are aiming to make ReBATE available for easy installation as a pip install python package.",
            "title": "Installing ReBATE"
        },
        {
            "location": "/installing/#prerequisites",
            "text": "All of the necessary Python packages can be installed via the  Anaconda Python distribution , which we strongly recommend that you use. We also strongly recommend that you use Python 3 over Python 2 if you're given the choice.  ReBATE requires that the following external Python packages be installed (all included in Anaconda):  argparse, time, sys, os, IO, Common, numpy, math, pandas, scipy.spatial.distance, operator, csv, distutils.core, distutils.extension, Cython.Distutils, datetime  NumPy and SciPy can be installed in Anaconda via the command:  conda install numpy scipy",
            "title": "Prerequisites"
        },
        {
            "location": "/installing/#additional-steps-for-windows-users",
            "text": "Here we discuss the additional prerequisites for running ReBATE on a Windows operating system. First you will need a command line terminal for Windows (e.g.  Cygwin , or  GitBash ) with Anaconda properly installed. From this terminal you can compile the Cython code, and run ReBATE. Second you will need a C compiler for compiling the Cython code once before being able to run ReBATE on your Windows machine.   There are a number of possible ways to get the C compiler working on your Windows terminal, all of which will depend on the version of windows, the version of python/Anaconda, and whether it is 32-bit or 64-bit. Be aware that there may be some troubleshooting in getting the C compiler operational in your command line terminal. Below we outline steps that worked for us in the spring of 2018 using Windows 10, and Python 3.5.2 with Anaconda 4.0 (64-bit), using GitBash as our terminal.  1.) Ensure that setuptools is updated. Run the following in your terminal:   pip install -upgrade setuptools  2.)  Download/install Visual Studio Community 2017 . This includes the necessary C compiler. It is not necessary to install all of the visual studio components, as this can be slow and take up a good deal of space. However make sure that you download and install the 'Desktop Development with C++' and the 'Python Development' workloads as detailed at the following  link .  Within the Python Development workload, also select the box on the right for Python native development tools.   3.) Once Visual Studio has been successfully installed, there was a remaining bug that required some troubleshooting for the C compiler to be found by the terminal. Try compiling Cython as described below and if it doesn't work try something like the following fix that worked for us:   (A)  Add this to your PATH environment variables : C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64     (B) Copy these two files (rc.exe and rcdll.dll) from (C:\\Program Files (x86)\\Windows Kits\\8.1\\bin\\x86) to (C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin)  4.) At this point you should be able to compile Cython as described below.",
            "title": "Additional Steps For Windows Users"
        },
        {
            "location": "/installing/#compile-cython",
            "text": "Once these prerequisites are installed, it will be necessary to compile the Cython code on the respective operating system within which ReBATE will be run. It is only necessary to do this once, not every time ReBATE is run. This happens in two stages (1) a .pyx file is compiled by cython to a .c file, then (2) the .c file is compiled by a C compiler to a .so file (or a .pyd file for Windows).   From the root directory simply run the following file included with ReBATE to produce the .c and (.so or .pyd) files:    ./make.sh  If there is need to recompile the Cython files, first remove the previous .c and (.so or .pyd) files run the following from the root directory:   ./clean.sh",
            "title": "Compile Cython"
        },
        {
            "location": "/using/",
            "text": "Using ReBATE\n\n\nThis section presumes that all ReBATE prerequisites have been properly \ninstalled\n. Also ensure that all commands below are run from the '/rebate/' directory. \n\n\nTo access the ReBATE help output (with all available run parameters and their default values), use the following command:\n\n\n./rebate.py -h\n\n\n\n\nBelow we provide an overview of the available ReBATE run parameters followed by code samples showing how the various Relief-based algorithms can be run.  Unlike \nscikit-rebate\n, ReBATE automatically outputs a text file with the feature names and their associated scores sorted by descending scores. For details on the algorithmic differences between the various Relief-based algorithms, please refer to \nthis research paper\n. \n\n\nAvailable ReBATE Parameters\n\n\nBelow we review the run parameters that can be specified (depending on the Relief-algorithm). \n\n\n\n\n\n\nParameter\n\n\nValid values\n\n\nEffect\n\n\n\n\n\n\n-a, --algorithm\n\n\nrelieff, surf, surfstar, multisurfstar, multisurf\n\n\nSpecify which Relief-based algorithm to use. We recommend 'multisurf', however 'relieff' is currently the most widely used variation. \n\n\n\n\n\n\n-c, --classname\n\n\nAny string entry\n\n\nSpecify the header name ReBATE should look for in the dataset to use as the the class/outcome variable. \n\n\n\n\n\n\n-d, --discretelimit\n\n\nAny positive integer\n\n\nValue used to determine if a feature is discrete or continuous. If the number of unique levels in a feature is > discrete_threshold, then it is considered continuous, or discrete otherwise.\n\n\n\n\n\n\n-f, --filename\n\n\nString with path/name\n\n\nPath/name of the training dataset to be used.\n\n\n\n\n\n\n-k, --knearestneighbors\n\n\nAny positive integer\n\n\nThe number of neighbors to consider when assigning feature importance scores. This parameter is only used by the 'relieff' algorithm. \n\n\n\n\n\n\n-m, --missingdata\n\n\nAny string entry\n\n\nSpecify the string that is uniformly used in the dataset to designate a missing value. \n\n\n\n\n\n\n-o, --outputdir\n\n\nString with path\n\n\nDirectory path to write output score text file. \n\n\n\n\n\n\n-T, --topattr\n\n\nPositive integer below training dataset feature count\n\n\nWhen specified, a new training data file is created with only the specified `top scoring' number of features. \n\n\n\n\n\n\n-t, --turflimit\n\n\nAny integer between 0 and 100\n\n\nActivates TuRF when value specified. Value controls percent of features removed each iteration, as well as inversely controls number of TuRF feature removal iterations. \n\n\n\n\n\n\n-x, --testdata\n\n\nString with path/name\n\n\nOnly used in conjunction with --topattr. When a file path/name is specified pointing to a testing dataset (generated by the user to pair with the given training dataset), ReBATE will also generate an output testing file that includes only the top attributes identified by the Relief-based algorithm scores on the training data. This is a convenience function.  \n\n\n\n\n\n\n\nExample Code\n\n\nFor all of the examples below, assume that the commands are being run from the root directory of ReBATE.  Included in ReBATE is a small directory of example datasets used by the unit testing called 'data'. We will use these datasets in the examples below. \n\n\nRelief\n\n\nRelief is the first, and most basic of the Relief-based feature selection algorithms. While ReBATE does not specifically implement the original Relief algorithm (i.e. notice that 'relief' is not an option for algorithm in the help output), an algorithm equivalent to Relief can be run by simply running 'relieff' and setting the parameter for 'number of nearest neighbors' to 1.  Example code for how to run Relief is as follows:\n\n\n./rebate.py -a relieff -f ../data/6Multiplexer_Data_500_0.txt -k 1\n\n\n\n\nThe .txt output file should now be in the folder named '/data/'. Note that the name of the outputfile includes (1) the name of the relief-based algorithm used, (2) the --discretelimit used, (3) the -k used, and (4) the name of the training dataset. \n\n\nAlso note that the following arguments were not specified for the given reasons: (1) '-c', since the class label is already the default 'Class' in this datset. (2) '-d', because all features have only 2 possible values (i.e. binary problem) thus the default setting of 10 ensures these features will be treated as discrete. (3) '-m', since there are no missing values in this dataset. (4) '-o', because we wanted the outputs to be saved to the corresponding data file directory. (5) '-T', because we didn't want a new filtered dataset saved. (6) '-t', because we didn't want to run the TuRF wrapper around Relief. (7) '-x', because we didn't run '-T', nor do we have an associated testing data available for this example. \n\n\nRelieff\n\n\nRelieff is currently the best known and most widely used Relief-based feature selection algorithm. Relieff requires you to specify the number of nearest neighbors that the algorithm will use for its feature scoring. Historically a default value of 10 has been used for k, however in datasets with 200 samples or more, \nevidence\n suggests that a k of 100 might be better by default. However for datasets with higher order feature interactions a smaller k is expected to perform better One thing is for clear, depending on the dataset, properly choosing k is important to optimal scoring. Since the given Multiplexer problem involves a 3-way feature interaction, we will use a smaller k here. Example code for how to run Relieff is as follows:\n\n\n./rebate.py -a relieff -f ../data/6Multiplexer_Data_500_0.txt -k 10\n\n\n\n\nOutput file naming and reasons for not using certain run parameters are the same as in the 'Relief' example. \n\n\nSURF\n\n\nSURF removed the need to specify the k parameter and was demonstrated to improve performance over Relieff to detect pure 2-way feature interactions. Example code for how to run SURF is as follows:\n\n\n./rebate.py -a surf -f ../data/6Multiplexer_Data_500_0.txt\n\n\n\n\nOutput file naming and reasons for not using certain run parameters are the same as in the 'Relief' example with the addition of '-k' no longer needing to be specified. \n\n\nSURF*\n\n\nSURF* expanded on SURF, adding the concept of 'far' scoring and was demonstrated to improve performance over SURF to detect pure 2-way feature interactions, however it performs poorly in detecting simple linear associations. Example code for how to run SURF* is as follows:\n\n\n./rebate.py -a surfstar -f ../data/6Multiplexer_Data_500_0.txt\n\n\n\n\nOutput file naming and reasons for not using certain run parameters are the same as in the 'Relief' example with the addition of '-k' no longer needing to be specified. \n\n\nMultiSURF*\n\n\nMultiSURF* expanded on SURF*, adding the deadband scoring zone, and target instance specific determinations of the nearest and farthest neighborhoods during scoring.  MultiSURF* was demonstrated to yield optimal performance to detect pure 2-way feature interactions, however it performs poorly in detecting simple linear associations. Example code for how to run MultiSURF* is as follows:\n\n\n./rebate.py -a multisurfstar -f ../data/6Multiplexer_Data_500_0.txt\n\n\n\n\nOutput file naming and reasons for not using certain run parameters are the same as in the 'Relief' example with the addition of '-k' no longer needing to be specified. \n\n\nMultiSURF\n\n\nMultiSURF is the newest of the Relief-based algorithms in ReBATE. It preserved the best aspects of MultiSURF*, but removed the far scoring thus restoring performance on detecting simple linear associations.  MultiSURF is currently recommended as the and most well rounded Relief-based algorithm available in ReBATE. Example code for how to run MultiSURF is as follows:\n\n\n./rebate.py -a multisurf -f ../data/6Multiplexer_Data_500_0.txt\n\n\n\n\nOutput file naming and reasons for not using certain run parameters are the same as in the 'Relief' example with the addition of '-k' no longer needing to be specified. \n\n\nTuRF with any other 'Core' algorithm\n\n\nTuRF is a wrapper method that can be combined with any of the core Relief-based methods (i.e. Relief, Relieff, SURF, SURF*, MultiSURF*, and MultiSURF). TuRF iteratively runs a given Relief-based algorithm, each time removing the lowest scoring percentage of features, and the re-scoring using the remaining features. Using an iterative Relief approach like TuRF is particularly important in very large feature spaces (e.g. any feature space larger than 10,000 features). It is expected that TuRF will improve the quality of feature scores even in smaller feature spaces, assuming that relevant features are not removed in a given TuRF iteration. In the examples below, a TuRF percent of 50 was used. This means that after the first iteration, 50% of the features will be removed from scoring.  This also means two iterations will be completed (i.e 1/(50/100)). Had we specified 25%, then TuRF would run for 4 iterations (i.e. 1/(25/100)).  Example code for how to run TuRF with the different core algorithms is as follows:\n\n\n./rebate.py -a relieff -f ../data/GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.txt -k 100 -t 50\n./rebate.py -a surf -f ../data/GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.txt -t 50\n./rebate.py -a surfstar -f ../data/GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.txt -t 50\n./rebate.py -a multisurfstar -f ../data/GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.txt -t 50\n./rebate.py -a multisurf -f ../data/GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.txt -t 50\n\n\n\n\nNote that in the associated score file that all original features are included, but only those that made the final TuRF cut are numbered in the far right column.  Those that were eliminated during a given iteration are indicated by a '*'.  Further, you can identify which features were more recently removed based on their associated feature score. Notably these scores are not accurate Relief scores (since they are automatically generated for a filtered-out features), but instead only provided to indicate when those features were filtered out.  All filtered out features are guarenteed to have a score lowerer than the lowest scoring feature in the final TuRF run.  Filtered out features with lower values were filtered out in earlier TuRF iterations (i.e. the features with the lowest scores were filtered out in the first iteration).  \n\n\nThe .txt output file should now be in the folder named '/data/'. Note that the name of the outputfile includes (1) the name of the relief-based algorithm used + TuRF, (2) the --discretelimit used, (3) the -k used, (4) the TuRF percentage used, and (5) the name of the training dataset. \n\n\nOther Examples\n\n\nWe conclude with some additional examples for running ReBATE in some other special cases.  For simplicity we will only give examples using the 'MultiSURF' algorithm. \n\n\nSpecify a different class label:\n\n\n./rebate.py -a multisurf -f ../data/6Multiplexer_Data_500_0.txt -c Class\n\n\n\n\nNote that 'Class' is also the default, but can be substituted with the appropriate label used in your dataset (e.g. 'Status', 'Outcome', etc.)\n\n\nSpecify a different missing value identifier:\n\n\n./rebate.py -a multisurf -f ../data/GAMETES_Epistasis_2-Way_missing_values_0.1_a_20s_1600her_0.4__maf_0.2_EDM-2_01.txt -m NA\n\n\n\n\nNote that 'NA' is also the default, but can be substituted with an appropriate text value (e.g. 'N/A', 'None', etc.) We strongly recommend formatting your dataset with a uniform alphabetic identifier prior to running ReBATE. \n\n\nOutput a new filtered dataset (with and without an associated testing dataset):\n\n\nIn addition to the scores, output a filtered training dataset with only 2 features, out of the 20 in the given dataset. \n\n\n./rebate.py -a multisurf -f ../data/GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.txt -T 2\n\n\n\n\nIn addition to the scores, output both a filtered training dataset with only 2 features, and a filtered testing dataset with the same 2 features.  Note that the respective Relief algorithm does not train on the testing data, but only uses it to make a new filtered testing dataset. Since we don't currently have a testing dataset available in our data folder we just specified the training data again, however you should ensure to give the path/name to the corresponding testing dataset instead.\n\n\n./rebate.py -a multisurf -f ../data/GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.txt -T 2 -x data/GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.txt\n\n\n\n\nNote that ReBATE automatically checks that the same feature set is present in both the training and testing datasets before running, and it will throw an error if the two datasets are not compatable. \n\n\nGeneral Usage Guidelines\n\n\n1.) When performing feature selection, there is no universally best way to determine where to draw the cuttoff for including features. When using original Relief or ReliefF it has been suggested that features yielding a negative value score, can be confidently filtered out. This guideline is believed to be extendable to SURF, SURF*, MultiSURF*, and MultiSURF, however please note that features with a negative score are not necessarily irrelevant, and those with a positive score are not necessarily relevant. Instead, scores are most effectively interpreted as the relative evidence that a given feature is predictive of outcome. Thus, while it may be reasonable to only filter out features with a negative score, in practice it may be more useful to select some 'top' number of features to pass onto modeling. \n\n\n2.) In very large feature spaces users can expect core Relief-based algorithm scores to become less reliable when run on their own. This is because as the feature space becomes very large, the determination of nearest neighbors becomes more random.  As a result, in very large feature spaces (e.g. > 10,000 features), users should consider combining a core Relief-based algorithm with an iterative approach such as TuRF (implemented here) or VLSRelieF, or Iterative Relief. \n\n\n3.) When scaling up to big data problems, keep in mind that the data aspect that slows down ReBATE methods the most is the number of training instances, since Relief algorithms scale linearly with the number of features, but quadratically with the number of training instances. This is is the result of Relief-based methods needing to calculate a distance array (i.e. all pairwise distances between instances in the training dataset).  If you have a very large number of training instances available, consider utilizing a class balanced random sampling of that dataset when running any ReBATE methods to save on memory and computational time.",
            "title": "Using ReBATE"
        },
        {
            "location": "/using/#using-rebate",
            "text": "This section presumes that all ReBATE prerequisites have been properly  installed . Also ensure that all commands below are run from the '/rebate/' directory.   To access the ReBATE help output (with all available run parameters and their default values), use the following command:  ./rebate.py -h  Below we provide an overview of the available ReBATE run parameters followed by code samples showing how the various Relief-based algorithms can be run.  Unlike  scikit-rebate , ReBATE automatically outputs a text file with the feature names and their associated scores sorted by descending scores. For details on the algorithmic differences between the various Relief-based algorithms, please refer to  this research paper .",
            "title": "Using ReBATE"
        },
        {
            "location": "/using/#available-rebate-parameters",
            "text": "Below we review the run parameters that can be specified (depending on the Relief-algorithm).     Parameter  Valid values  Effect    -a, --algorithm  relieff, surf, surfstar, multisurfstar, multisurf  Specify which Relief-based algorithm to use. We recommend 'multisurf', however 'relieff' is currently the most widely used variation.     -c, --classname  Any string entry  Specify the header name ReBATE should look for in the dataset to use as the the class/outcome variable.     -d, --discretelimit  Any positive integer  Value used to determine if a feature is discrete or continuous. If the number of unique levels in a feature is > discrete_threshold, then it is considered continuous, or discrete otherwise.    -f, --filename  String with path/name  Path/name of the training dataset to be used.    -k, --knearestneighbors  Any positive integer  The number of neighbors to consider when assigning feature importance scores. This parameter is only used by the 'relieff' algorithm.     -m, --missingdata  Any string entry  Specify the string that is uniformly used in the dataset to designate a missing value.     -o, --outputdir  String with path  Directory path to write output score text file.     -T, --topattr  Positive integer below training dataset feature count  When specified, a new training data file is created with only the specified `top scoring' number of features.     -t, --turflimit  Any integer between 0 and 100  Activates TuRF when value specified. Value controls percent of features removed each iteration, as well as inversely controls number of TuRF feature removal iterations.     -x, --testdata  String with path/name  Only used in conjunction with --topattr. When a file path/name is specified pointing to a testing dataset (generated by the user to pair with the given training dataset), ReBATE will also generate an output testing file that includes only the top attributes identified by the Relief-based algorithm scores on the training data. This is a convenience function.",
            "title": "Available ReBATE Parameters"
        },
        {
            "location": "/using/#example-code",
            "text": "For all of the examples below, assume that the commands are being run from the root directory of ReBATE.  Included in ReBATE is a small directory of example datasets used by the unit testing called 'data'. We will use these datasets in the examples below.",
            "title": "Example Code"
        },
        {
            "location": "/using/#relief",
            "text": "Relief is the first, and most basic of the Relief-based feature selection algorithms. While ReBATE does not specifically implement the original Relief algorithm (i.e. notice that 'relief' is not an option for algorithm in the help output), an algorithm equivalent to Relief can be run by simply running 'relieff' and setting the parameter for 'number of nearest neighbors' to 1.  Example code for how to run Relief is as follows:  ./rebate.py -a relieff -f ../data/6Multiplexer_Data_500_0.txt -k 1  The .txt output file should now be in the folder named '/data/'. Note that the name of the outputfile includes (1) the name of the relief-based algorithm used, (2) the --discretelimit used, (3) the -k used, and (4) the name of the training dataset.   Also note that the following arguments were not specified for the given reasons: (1) '-c', since the class label is already the default 'Class' in this datset. (2) '-d', because all features have only 2 possible values (i.e. binary problem) thus the default setting of 10 ensures these features will be treated as discrete. (3) '-m', since there are no missing values in this dataset. (4) '-o', because we wanted the outputs to be saved to the corresponding data file directory. (5) '-T', because we didn't want a new filtered dataset saved. (6) '-t', because we didn't want to run the TuRF wrapper around Relief. (7) '-x', because we didn't run '-T', nor do we have an associated testing data available for this example.",
            "title": "Relief"
        },
        {
            "location": "/using/#relieff",
            "text": "Relieff is currently the best known and most widely used Relief-based feature selection algorithm. Relieff requires you to specify the number of nearest neighbors that the algorithm will use for its feature scoring. Historically a default value of 10 has been used for k, however in datasets with 200 samples or more,  evidence  suggests that a k of 100 might be better by default. However for datasets with higher order feature interactions a smaller k is expected to perform better One thing is for clear, depending on the dataset, properly choosing k is important to optimal scoring. Since the given Multiplexer problem involves a 3-way feature interaction, we will use a smaller k here. Example code for how to run Relieff is as follows:  ./rebate.py -a relieff -f ../data/6Multiplexer_Data_500_0.txt -k 10  Output file naming and reasons for not using certain run parameters are the same as in the 'Relief' example.",
            "title": "Relieff"
        },
        {
            "location": "/using/#surf",
            "text": "SURF removed the need to specify the k parameter and was demonstrated to improve performance over Relieff to detect pure 2-way feature interactions. Example code for how to run SURF is as follows:  ./rebate.py -a surf -f ../data/6Multiplexer_Data_500_0.txt  Output file naming and reasons for not using certain run parameters are the same as in the 'Relief' example with the addition of '-k' no longer needing to be specified.",
            "title": "SURF"
        },
        {
            "location": "/using/#surf_1",
            "text": "SURF* expanded on SURF, adding the concept of 'far' scoring and was demonstrated to improve performance over SURF to detect pure 2-way feature interactions, however it performs poorly in detecting simple linear associations. Example code for how to run SURF* is as follows:  ./rebate.py -a surfstar -f ../data/6Multiplexer_Data_500_0.txt  Output file naming and reasons for not using certain run parameters are the same as in the 'Relief' example with the addition of '-k' no longer needing to be specified.",
            "title": "SURF*"
        },
        {
            "location": "/using/#multisurf",
            "text": "MultiSURF* expanded on SURF*, adding the deadband scoring zone, and target instance specific determinations of the nearest and farthest neighborhoods during scoring.  MultiSURF* was demonstrated to yield optimal performance to detect pure 2-way feature interactions, however it performs poorly in detecting simple linear associations. Example code for how to run MultiSURF* is as follows:  ./rebate.py -a multisurfstar -f ../data/6Multiplexer_Data_500_0.txt  Output file naming and reasons for not using certain run parameters are the same as in the 'Relief' example with the addition of '-k' no longer needing to be specified.",
            "title": "MultiSURF*"
        },
        {
            "location": "/using/#multisurf_1",
            "text": "MultiSURF is the newest of the Relief-based algorithms in ReBATE. It preserved the best aspects of MultiSURF*, but removed the far scoring thus restoring performance on detecting simple linear associations.  MultiSURF is currently recommended as the and most well rounded Relief-based algorithm available in ReBATE. Example code for how to run MultiSURF is as follows:  ./rebate.py -a multisurf -f ../data/6Multiplexer_Data_500_0.txt  Output file naming and reasons for not using certain run parameters are the same as in the 'Relief' example with the addition of '-k' no longer needing to be specified.",
            "title": "MultiSURF"
        },
        {
            "location": "/using/#turf-with-any-other-core-algorithm",
            "text": "TuRF is a wrapper method that can be combined with any of the core Relief-based methods (i.e. Relief, Relieff, SURF, SURF*, MultiSURF*, and MultiSURF). TuRF iteratively runs a given Relief-based algorithm, each time removing the lowest scoring percentage of features, and the re-scoring using the remaining features. Using an iterative Relief approach like TuRF is particularly important in very large feature spaces (e.g. any feature space larger than 10,000 features). It is expected that TuRF will improve the quality of feature scores even in smaller feature spaces, assuming that relevant features are not removed in a given TuRF iteration. In the examples below, a TuRF percent of 50 was used. This means that after the first iteration, 50% of the features will be removed from scoring.  This also means two iterations will be completed (i.e 1/(50/100)). Had we specified 25%, then TuRF would run for 4 iterations (i.e. 1/(25/100)).  Example code for how to run TuRF with the different core algorithms is as follows:  ./rebate.py -a relieff -f ../data/GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.txt -k 100 -t 50\n./rebate.py -a surf -f ../data/GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.txt -t 50\n./rebate.py -a surfstar -f ../data/GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.txt -t 50\n./rebate.py -a multisurfstar -f ../data/GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.txt -t 50\n./rebate.py -a multisurf -f ../data/GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.txt -t 50  Note that in the associated score file that all original features are included, but only those that made the final TuRF cut are numbered in the far right column.  Those that were eliminated during a given iteration are indicated by a '*'.  Further, you can identify which features were more recently removed based on their associated feature score. Notably these scores are not accurate Relief scores (since they are automatically generated for a filtered-out features), but instead only provided to indicate when those features were filtered out.  All filtered out features are guarenteed to have a score lowerer than the lowest scoring feature in the final TuRF run.  Filtered out features with lower values were filtered out in earlier TuRF iterations (i.e. the features with the lowest scores were filtered out in the first iteration).    The .txt output file should now be in the folder named '/data/'. Note that the name of the outputfile includes (1) the name of the relief-based algorithm used + TuRF, (2) the --discretelimit used, (3) the -k used, (4) the TuRF percentage used, and (5) the name of the training dataset.",
            "title": "TuRF with any other 'Core' algorithm"
        },
        {
            "location": "/using/#other-examples",
            "text": "We conclude with some additional examples for running ReBATE in some other special cases.  For simplicity we will only give examples using the 'MultiSURF' algorithm.",
            "title": "Other Examples"
        },
        {
            "location": "/using/#specify-a-different-class-label",
            "text": "./rebate.py -a multisurf -f ../data/6Multiplexer_Data_500_0.txt -c Class  Note that 'Class' is also the default, but can be substituted with the appropriate label used in your dataset (e.g. 'Status', 'Outcome', etc.)",
            "title": "Specify a different class label:"
        },
        {
            "location": "/using/#specify-a-different-missing-value-identifier",
            "text": "./rebate.py -a multisurf -f ../data/GAMETES_Epistasis_2-Way_missing_values_0.1_a_20s_1600her_0.4__maf_0.2_EDM-2_01.txt -m NA  Note that 'NA' is also the default, but can be substituted with an appropriate text value (e.g. 'N/A', 'None', etc.) We strongly recommend formatting your dataset with a uniform alphabetic identifier prior to running ReBATE.",
            "title": "Specify a different missing value identifier:"
        },
        {
            "location": "/using/#output-a-new-filtered-dataset-with-and-without-an-associated-testing-dataset",
            "text": "In addition to the scores, output a filtered training dataset with only 2 features, out of the 20 in the given dataset.   ./rebate.py -a multisurf -f ../data/GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.txt -T 2  In addition to the scores, output both a filtered training dataset with only 2 features, and a filtered testing dataset with the same 2 features.  Note that the respective Relief algorithm does not train on the testing data, but only uses it to make a new filtered testing dataset. Since we don't currently have a testing dataset available in our data folder we just specified the training data again, however you should ensure to give the path/name to the corresponding testing dataset instead.  ./rebate.py -a multisurf -f ../data/GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.txt -T 2 -x data/GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.txt  Note that ReBATE automatically checks that the same feature set is present in both the training and testing datasets before running, and it will throw an error if the two datasets are not compatable.",
            "title": "Output a new filtered dataset (with and without an associated testing dataset):"
        },
        {
            "location": "/using/#general-usage-guidelines",
            "text": "1.) When performing feature selection, there is no universally best way to determine where to draw the cuttoff for including features. When using original Relief or ReliefF it has been suggested that features yielding a negative value score, can be confidently filtered out. This guideline is believed to be extendable to SURF, SURF*, MultiSURF*, and MultiSURF, however please note that features with a negative score are not necessarily irrelevant, and those with a positive score are not necessarily relevant. Instead, scores are most effectively interpreted as the relative evidence that a given feature is predictive of outcome. Thus, while it may be reasonable to only filter out features with a negative score, in practice it may be more useful to select some 'top' number of features to pass onto modeling.   2.) In very large feature spaces users can expect core Relief-based algorithm scores to become less reliable when run on their own. This is because as the feature space becomes very large, the determination of nearest neighbors becomes more random.  As a result, in very large feature spaces (e.g. > 10,000 features), users should consider combining a core Relief-based algorithm with an iterative approach such as TuRF (implemented here) or VLSRelieF, or Iterative Relief.   3.) When scaling up to big data problems, keep in mind that the data aspect that slows down ReBATE methods the most is the number of training instances, since Relief algorithms scale linearly with the number of features, but quadratically with the number of training instances. This is is the result of Relief-based methods needing to calculate a distance array (i.e. all pairwise distances between instances in the training dataset).  If you have a very large number of training instances available, consider utilizing a class balanced random sampling of that dataset when running any ReBATE methods to save on memory and computational time.",
            "title": "General Usage Guidelines"
        },
        {
            "location": "/contributing/",
            "text": "Contributing to ReBATE\n\n\nWe welcome you to \ncheck the existing issues\n for bugs or enhancements to work on. If you have an idea for an extension to ReBATE, please \nfile a new issue\n so we can discuss it.\n\n\nProject layout\n\n\nThe latest stable release of ReBATE is on the \nmaster branch\n, whereas the latest version of scikit-rebate in development is on the \ndevelopment branch\n. Make sure you are looking at and working on the correct branch if you're looking to contribute code.\n\n\nIn terms of directory structure:\n\n\n\n\nAll of ReBATE's code sources are in the base directory\n\n\nThe documentation sources are in the \ndocs_sources\n directory\n\n\nThe latest documentation build is in the \ndocs\n directory\n\n\nUnit tests for ReBATE are in the \ntests.py\n file\n\n\n\n\nMake sure to familiarize yourself with the project layout before making any major contributions, and especially make sure to send all code changes to the \ndevelopment\n branch.\n\n\nHow to contribute\n\n\nThe preferred way to contribute to ReBATE is to fork the\n\nmain repository\n on\nGitHub:\n\n\n\n\n\n\nFork the \nproject repository\n:\n   click on the 'Fork' button near the top of the page. This creates\n   a copy of the code under your account on the GitHub server.\n\n\n\n\n\n\nClone this copy to your local disk:\n\n\n  $ git clone git@github.com:YourLogin/ReBATE.git\n  $ cd ReBATE\n\n\n\n\n\n\n\nCreate a branch to hold your changes:\n\n\n  $ git checkout -b my-contribution\n\n\n\n\n\n\n\nMake sure your local environment is setup correctly for development. Installation instructions are almost identical to \nthe user instructions\n except that ReBATE should \nnot\n be installed. If you have ReBATE installed on your computer, then make sure you are using a virtual environment that does not have ReBATE installed. Furthermore, you should make sure you have installed the \nnose\n package into your development environment so that you can test changes locally.\n\n\n  $ conda install nose\n\n\n\n\n\n\n\nStart making changes on your newly created branch, remembering to never work on the \nmaster\n branch! Work on this copy on your computer using Git to do the version control.\n\n\n\n\n\n\nOnce some changes are saved locally, you can use your tweaked version of ReBATE by navigating to the project's base directory and rebuild ReBATE in a script.\n\n\n  $ ./clean.sh\n  $ ./make.sh\n\n\n\n\n\n\n\nTo check your changes haven't broken any existing tests and to check new tests you've added pass run the following (note, you must have the \nnose\n package installed within your dev environment for this to work):\n\n\n  $ nosetests -s -v\n\n\n\n\n\n\n\nWhen you're done editing and local testing, run:\n\n\n  $ git add modified_files\n  $ git commit\n\n\n\n\n\n\n\nto record your changes in Git, then push them to GitHub with:\n\n\n      $ git push -u origin my-contribution\n\n\n\nFinally, go to the web page of your fork of the ReBATE repo, and click 'Pull Request' (PR) to send your changes to the maintainers for review. Make sure that you send your PR to the \ndevelopment\n branch, as the \nmaster\n branch is reserved for the latest stable release. This will start the CI server to check all the project's unit tests run and send an email to the maintainers.\n\n\n(For details on the above look up the \nGit documentation\n on the web.)\n\n\nBefore submitting your pull request\n\n\nBefore you submit a pull request for your contribution, please work through this checklist to make sure that you have done everything necessary so we can efficiently review and accept your changes.\n\n\nIf your contribution changes ReBATE in any way:\n\n\n\n\n\n\nUpdate the \ndocumentation\n so all of your changes are reflected there.\n\n\n\n\n\n\nUpdate the \nREADME\n if anything there has changed.\n\n\n\n\n\n\nIf your contribution involves any code changes:\n\n\n\n\n\n\nUpdate the \nproject unit tests\n to test your code changes.\n\n\n\n\n\n\nMake sure that your code is properly commented with \ndocstrings\n and comments explaining your rationale behind non-obvious coding practices.\n\n\n\n\n\n\nIf your contribution requires a new library dependency:\n\n\n\n\n\n\nDouble-check that the new dependency is easy to install via \npip\n or Anaconda and supports both Python 2 and 3. If the dependency requires a complicated installation, then we most likely won't merge your changes because we want to keep ReBATE easy to install.\n\n\n\n\n\n\nAdd a line to pip install the library to \n.travis_install.sh\n\n\n\n\n\n\nAdd a line to print the version of the library to \n.travis_install.sh\n\n\n\n\n\n\nSimilarly add a line to print the version of the library to \n.travis_test.sh\n\n\n\n\n\n\nUpdating the documentation\n\n\nWe use \nmkdocs\n to manage our \ndocumentation\n. This allows us to write the docs in Markdown and compile them to HTML as needed. Below are a few useful commands to know when updating the documentation. Make sure that you are running them in the base repository directory.  \n\n\n\n\n\n\npip install mkdocs\n: Install mkdocs, if you don't already have it. (can be run from anywhere)\n\n\n\n\n\n\nmkdocs serve\n: Hosts of a local version of the documentation that you can access at the provided URL. The local version will update automatically as you save changes to the documentation.\n\n\n\n\n\n\nmkdocs build --clean\n: Creates a fresh build of the documentation in HTML. Always run this before deploying the documentation to GitHub.\n\n\n\n\n\n\nmkdocs gh-deploy\n: Deploys the documentation to GitHub. If you're deploying on your fork of ReBATE, the online documentation should be accessible at \nhttp://<YOUR GITHUB USERNAME>.github.io/ReBATE/\n. Generally, you shouldn't need to run this command because you can view your changes with \nmkdocs serve\n.\n\n\n\n\n\n\nAfter submitting your pull request\n\n\nAfter submitting your pull request, \nTravis-CI\n will automatically run unit tests on your changes and make sure that your updated code builds and runs on Python 2 and 3. We also use services that automatically check code quality and test coverage.\n\n\nCheck back shortly after submitting your pull request to make sure that your code passes these checks. If any of the checks come back with a red X, then do your best to address the errors.",
            "title": "Contributing"
        },
        {
            "location": "/contributing/#contributing-to-rebate",
            "text": "We welcome you to  check the existing issues  for bugs or enhancements to work on. If you have an idea for an extension to ReBATE, please  file a new issue  so we can discuss it.",
            "title": "Contributing to ReBATE"
        },
        {
            "location": "/contributing/#project-layout",
            "text": "The latest stable release of ReBATE is on the  master branch , whereas the latest version of scikit-rebate in development is on the  development branch . Make sure you are looking at and working on the correct branch if you're looking to contribute code.  In terms of directory structure:   All of ReBATE's code sources are in the base directory  The documentation sources are in the  docs_sources  directory  The latest documentation build is in the  docs  directory  Unit tests for ReBATE are in the  tests.py  file   Make sure to familiarize yourself with the project layout before making any major contributions, and especially make sure to send all code changes to the  development  branch.",
            "title": "Project layout"
        },
        {
            "location": "/contributing/#how-to-contribute",
            "text": "The preferred way to contribute to ReBATE is to fork the main repository  on\nGitHub:    Fork the  project repository :\n   click on the 'Fork' button near the top of the page. This creates\n   a copy of the code under your account on the GitHub server.    Clone this copy to your local disk:    $ git clone git@github.com:YourLogin/ReBATE.git\n  $ cd ReBATE    Create a branch to hold your changes:    $ git checkout -b my-contribution    Make sure your local environment is setup correctly for development. Installation instructions are almost identical to  the user instructions  except that ReBATE should  not  be installed. If you have ReBATE installed on your computer, then make sure you are using a virtual environment that does not have ReBATE installed. Furthermore, you should make sure you have installed the  nose  package into your development environment so that you can test changes locally.    $ conda install nose    Start making changes on your newly created branch, remembering to never work on the  master  branch! Work on this copy on your computer using Git to do the version control.    Once some changes are saved locally, you can use your tweaked version of ReBATE by navigating to the project's base directory and rebuild ReBATE in a script.    $ ./clean.sh\n  $ ./make.sh    To check your changes haven't broken any existing tests and to check new tests you've added pass run the following (note, you must have the  nose  package installed within your dev environment for this to work):    $ nosetests -s -v    When you're done editing and local testing, run:    $ git add modified_files\n  $ git commit    to record your changes in Git, then push them to GitHub with:        $ git push -u origin my-contribution  Finally, go to the web page of your fork of the ReBATE repo, and click 'Pull Request' (PR) to send your changes to the maintainers for review. Make sure that you send your PR to the  development  branch, as the  master  branch is reserved for the latest stable release. This will start the CI server to check all the project's unit tests run and send an email to the maintainers.  (For details on the above look up the  Git documentation  on the web.)",
            "title": "How to contribute"
        },
        {
            "location": "/contributing/#before-submitting-your-pull-request",
            "text": "Before you submit a pull request for your contribution, please work through this checklist to make sure that you have done everything necessary so we can efficiently review and accept your changes.  If your contribution changes ReBATE in any way:    Update the  documentation  so all of your changes are reflected there.    Update the  README  if anything there has changed.    If your contribution involves any code changes:    Update the  project unit tests  to test your code changes.    Make sure that your code is properly commented with  docstrings  and comments explaining your rationale behind non-obvious coding practices.    If your contribution requires a new library dependency:    Double-check that the new dependency is easy to install via  pip  or Anaconda and supports both Python 2 and 3. If the dependency requires a complicated installation, then we most likely won't merge your changes because we want to keep ReBATE easy to install.    Add a line to pip install the library to  .travis_install.sh    Add a line to print the version of the library to  .travis_install.sh    Similarly add a line to print the version of the library to  .travis_test.sh",
            "title": "Before submitting your pull request"
        },
        {
            "location": "/contributing/#updating-the-documentation",
            "text": "We use  mkdocs  to manage our  documentation . This allows us to write the docs in Markdown and compile them to HTML as needed. Below are a few useful commands to know when updating the documentation. Make sure that you are running them in the base repository directory.      pip install mkdocs : Install mkdocs, if you don't already have it. (can be run from anywhere)    mkdocs serve : Hosts of a local version of the documentation that you can access at the provided URL. The local version will update automatically as you save changes to the documentation.    mkdocs build --clean : Creates a fresh build of the documentation in HTML. Always run this before deploying the documentation to GitHub.    mkdocs gh-deploy : Deploys the documentation to GitHub. If you're deploying on your fork of ReBATE, the online documentation should be accessible at  http://<YOUR GITHUB USERNAME>.github.io/ReBATE/ . Generally, you shouldn't need to run this command because you can view your changes with  mkdocs serve .",
            "title": "Updating the documentation"
        },
        {
            "location": "/contributing/#after-submitting-your-pull-request",
            "text": "After submitting your pull request,  Travis-CI  will automatically run unit tests on your changes and make sure that your updated code builds and runs on Python 2 and 3. We also use services that automatically check code quality and test coverage.  Check back shortly after submitting your pull request to make sure that your code passes these checks. If any of the checks come back with a red X, then do your best to address the errors.",
            "title": "After submitting your pull request"
        },
        {
            "location": "/releases/",
            "text": "ReBATE 0.2\n\n\n\n\n\n\nAdded documentation with mkdocs.\n\n\n\n\n\n\nAdded unit testing. Adopted Travis CI\n\n\n\n\n\n\nAdded 'MultiSURF' algorithm, previously only available in scikit-rebate.\n\n\n\n\n\n\nUpdated ReBATE to include other updates made to scikit-rebate. \n\n\n\n\n\n\nFixed score normalizations so they fall between -1 and 1 for all algorithms Now matches scikit-rebate.\n\n\n\n\n\n\nConsolidated MultiSURF* so that one script is used for both multiclass, and other types of endpoints. \n\n\n\n\n\n\nAdded an automatic (standard deviation based) ramp function method that is utilized by all algorithms on data with a mix of discrete and continuous features. Taken from scikit-rebate.\n\n\n\n\n\n\nIncluded steps to support operation of ReBATE in Windows. \n\n\n\n\n\n\nBeyond what was previously used for testing scikit-rebate, we added the 6-bit multiplexer as a test problem as well as a simple 3-class (multiclass) GWAS-style simulated dataset (with 100% heritability). \n\n\n\n\n\n\nReBATE 0.1\n\n\n\n\nInitial release of Relief algorithms, including ReliefF, SURF, SURF*, MultSURF*, and TuRF.",
            "title": "Release Notes"
        },
        {
            "location": "/releases/#rebate-02",
            "text": "Added documentation with mkdocs.    Added unit testing. Adopted Travis CI    Added 'MultiSURF' algorithm, previously only available in scikit-rebate.    Updated ReBATE to include other updates made to scikit-rebate.     Fixed score normalizations so they fall between -1 and 1 for all algorithms Now matches scikit-rebate.    Consolidated MultiSURF* so that one script is used for both multiclass, and other types of endpoints.     Added an automatic (standard deviation based) ramp function method that is utilized by all algorithms on data with a mix of discrete and continuous features. Taken from scikit-rebate.    Included steps to support operation of ReBATE in Windows.     Beyond what was previously used for testing scikit-rebate, we added the 6-bit multiplexer as a test problem as well as a simple 3-class (multiclass) GWAS-style simulated dataset (with 100% heritability).",
            "title": "ReBATE 0.2"
        },
        {
            "location": "/releases/#rebate-01",
            "text": "Initial release of Relief algorithms, including ReliefF, SURF, SURF*, MultSURF*, and TuRF.",
            "title": "ReBATE 0.1"
        },
        {
            "location": "/citing/",
            "text": "If you use \nReBATE\n or the \nMultiSURF\n algorithm in a scientific publication, please consider citing the following paper (currently available as a pre-print in arXiv):\n\n\nUrbanowicz, Ryan J., Randal S. Olson, Peter Schmitt, Melissa Meeker, and Jason H. Moore. \"Benchmarking relief-based feature selection methods.\" arXiv preprint arXiv:1711.08477 (2017).\n\n\nAlternatively a complete \nreview of Relief-based algorithms\n is available at:\n\n\nUrbanowicz, Ryan J., Melissa Meeker, William LaCava, Randal S. Olson, and Jason H. Moore. \"Relief-based feature selection: introduction and review.\" arXiv preprint arXiv:1711.08421 (2017).\n\n\nTo cite the \noriginal Relief\n paper:\n\n\nKira, Kenji, and Larry A. Rendell. \"A practical approach to feature selection.\" In Machine Learning Proceedings 1992, pp. 249-256. 1992.\n\n\nTo cite the \noriginal ReliefF\n paper: \n\n\nKononenko, Igor. \"Estimating attributes: analysis and extensions of RELIEF.\" In European conference on machine learning, pp. 171-182. Springer, Berlin, Heidelberg, 1994.\n\n\nTo cite the \noriginal SURF\n paper:\n\n\nGreene, Casey S., Nadia M. Penrod, Jeff Kiralis, and Jason H. Moore. \"Spatially uniform relieff (SURF) for computationally-efficient filtering of gene-gene interactions.\" BioData mining 2, no. 1 (2009): 5.\n\n\nTo cite the \noriginal SURF*\n paper: \n\n\nGreene, Casey S., Daniel S. Himmelstein, Jeff Kiralis, and Jason H. Moore. \"The informative extremes: using both nearest and farthest individuals can improve relief algorithms in the domain of human genetics.\" In European Conference on Evolutionary Computation, Machine Learning and Data Mining in Bioinformatics, pp. 182-193. Springer, Berlin, Heidelberg, 2010.\n\n\nTo cite the \noriginal MultiSURF*\n paper:\n\n\nGranizo-Mackenzie, Delaney, and Jason H. Moore. \"Multiple threshold spatially uniform relieff for the genetic analysis of complex human diseases.\" In European Conference on Evolutionary Computation, Machine Learning and Data Mining in Bioinformatics, pp. 1-10. Springer, Berlin, Heidelberg, 2013.\n\n\nTo cite the \noriginal TuRF\n paper: \n\n\nMoore, Jason H., and Bill C. White. \"Tuning ReliefF for genome-wide genetic analysis.\" In European Conference on Evolutionary Computation, Machine Learning and Data Mining in Bioinformatics, pp. 166-175. Springer, Berlin, Heidelberg, 2007.",
            "title": "Citing"
        },
        {
            "location": "/support/",
            "text": "ReBATE was developed in the \nComputational Genetics Lab\n with funding from the \nNIH\n. We are incredibly grateful for their support during the development of this project.",
            "title": "Support"
        }
    ]
}