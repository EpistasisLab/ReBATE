{
    "docs": [
        {
            "location": "/",
            "text": "scikit-rebate\n is a scikit-learn-compatible Python implementation of ReBATE, a suite of \nRelief\n-based feature selection algorithms for Machine Learning. \nThis project is still under active development\n and we encourage you to check back on this repository regularly for updates.\n\n\nThese algorithms excel at identifying features that are predictive of the outcome in supervised learning problems, and are especially good at identifying feature interactions that are normally overlooked by standard feature selection methods.\n\n\nThe main benefit of Relief-based algorithms is that they identify feature interactions without having to exhaustively check every pairwise interaction, thus taking significantly less time than exhaustive pairwise search.\n\n\nRelief-based algorithms are commonly applied to genetic analyses, where epistasis (i.e., feature interactions) is common. However, the algorithms implemented in this package can be applied to almost any supervised classification data set and supports:\n\n\n\n\n\n\nA mix of categorical and/or continuous features\n\n\n\n\n\n\nData with missing values\n\n\n\n\n\n\nBinary endpoints (i.e., classification)\n\n\n\n\n\n\nMulti-class endpoints (i.e., classification)\n\n\n\n\n\n\nContinuous endpoints (i.e., regression)",
            "title": "Home"
        },
        {
            "location": "/installing/",
            "text": "scikit-rebate is built on top of the following existing Python packages:\n\n\n\n\n\n\nNumPy\n\n\n\n\n\n\nSciPy\n\n\n\n\n\n\nscikit-learn\n\n\n\n\n\n\nAll of the necessary Python packages can be installed via the \nAnaconda Python distribution\n, which we strongly recommend that you use. We also strongly recommend that you use Python 3 over Python 2 if you're given the choice.\n\n\nNumPy, SciPy, and scikit-learn can be installed in Anaconda via the command:\n\n\nconda install numpy scipy scikit-learn\n\n\n\n\nOnce the prerequisites are installed, you should be able to install scikit-rebate with a pip command:\n\n\npip install skrebate\n\n\n\n\nPlease \nfile a new issue\n if you run into installation problems.",
            "title": "Installation"
        },
        {
            "location": "/using/",
            "text": "We have designed the Relief algorithms to be integrated directly into scikit-learn machine learning workflows. Below, we provide code samples showing how the various Relief algorithms can be used as feature selection methods in scikit-learn pipelines.\n\n\nFor details on the algorithmic differences between the various Relief algorithms, please refer to \nthis research paper\n.\n\n\nReliefF\n\n\nReliefF is the most basic of the Relief-based feature selection algorithms, and it requires you to specify the number of nearest neighbors to consider in the scoring algorithm. The parameters for the ReliefF algorithm are as follows:\n\n\n\n\n\n\nParameter\n\n\nValid values\n\n\nEffect\n\n\n\n\n\n\nn_features_to_select\n\n\nAny positive integer or float\n\n\nThe number of best features to retain after the feature selection process. The \"best\" features are the highest-scored features according to the ReliefF scoring process.\n\n\n\n\n\n\nn_neighbors\n\n\nAny positive integer\n\n\nThe number of neighbors to consider when assigning feature importance scores. If a float number is provided, that percentage of training samples is used as the number of neighbors. More neighbors results in more accurate scores, but takes longer.\n\n\n\n\n\n\ndiscrete_limit\n\n\nAny positive integer\n\n\nValue used to determine if a feature is discrete or continuous. If the number of unique levels in a feature is > discrete_threshold, then it is considered continuous, or discrete otherwise.\n\n\n\n\n\n\nn_jobs\n\n\nAny positive integer or -1\n\n\nThe number cores to dedicate to running the algorithm in parallel with joblib. Set to -1 to use all available cores.\n\n\n\n\n\n\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom skrebate import ReliefF\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\ngenetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'\n                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.tsv.gz',\n                           sep='\\t', compression='gzip')\n\nfeatures, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values\n\nclf = make_pipeline(ReliefF(n_features_to_select=2, n_neighbors=100),\n                    RandomForestClassifier(n_estimators=100))\n\nprint(np.mean(cross_val_score(clf, features, labels)))\n>>> 0.795\n\n\n\n\nSURF\n\n\nSURF, SURF*, and MultiSURF are all extensions to the ReliefF algorithm that automatically determine the ideal number of neighbors to consider when scoring the features.\n\n\n\n\n\n\nParameter\n\n\nValid values\n\n\nEffect\n\n\n\n\n\n\nn_features_to_select\n\n\nAny positive integer\n\n\nThe number of best features to retain after the feature selection process. The \"best\" features are the highest-scored features according to the SURF scoring process.\n\n\n\n\n\n\ndiscrete_limit\n\n\nAny positive integer\n\n\nValue used to determine if a feature is discrete or continuous. If the number of unique levels in a feature is > discrete_threshold, then it is considered continuous, or discrete otherwise.\n\n\n\n\n\n\nn_jobs\n\n\nAny positive integer or -1\n\n\nThe number cores to dedicate to running the algorithm in parallel with joblib. Set to -1 to use all available cores.\n\n\n\n\n\n\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom skrebate import SURF\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\ngenetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'\n                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.tsv.gz',\n                           sep='\\t', compression='gzip')\n\nfeatures, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values\n\nclf = make_pipeline(SURF(n_features_to_select=2),\n                    RandomForestClassifier(n_estimators=100))\n\nprint(np.mean(cross_val_score(clf, features, labels)))\n>>> 0.795\n\n\n\n\nSURF*\n\n\n\n\n\n\nParameter\n\n\nValid values\n\n\nEffect\n\n\n\n\n\n\nn_features_to_select\n\n\nAny positive integer\n\n\nThe number of best features to retain after the feature selection process. The \"best\" features are the highest-scored features according to the SURF* scoring process.\n\n\n\n\n\n\ndiscrete_limit\n\n\nAny positive integer\n\n\nValue used to determine if a feature is discrete or continuous. If the number of unique levels in a feature is > discrete_threshold, then it is considered continuous, or discrete otherwise.\n\n\n\n\n\n\nn_jobs\n\n\nAny positive integer or -1\n\n\nThe number cores to dedicate to running the algorithm in parallel with joblib. Set to -1 to use all available cores.\n\n\n\n\n\n\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom skrebate import SURFstar\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\ngenetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'\n                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.tsv.gz',\n                           sep='\\t', compression='gzip')\n\nfeatures, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values\n\nclf = make_pipeline(SURFstar(n_features_to_select=2),\n                    RandomForestClassifier(n_estimators=100))\n\nprint(np.mean(cross_val_score(clf, features, labels)))\n>>> 0.795\n\n\n\n\nMultiSURF\n\n\n\n\n\n\nParameter\n\n\nValid values\n\n\nEffect\n\n\n\n\n\n\nn_features_to_select\n\n\nAny positive integer\n\n\nThe number of best features to retain after the feature selection process. The \"best\" features are the highest-scored features according to the MultiSURF scoring process.\n\n\n\n\n\n\ndiscrete_limit\n\n\nAny positive integer\n\n\nValue used to determine if a feature is discrete or continuous. If the number of unique levels in a feature is > discrete_threshold, then it is considered continuous, or discrete otherwise.\n\n\n\n\n\n\nn_jobs\n\n\nAny positive integer or -1\n\n\nThe number cores to dedicate to running the algorithm in parallel with joblib. Set to -1 to use all available cores.\n\n\n\n\n\n\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom skrebate import MultiSURF\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\ngenetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'\n                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.tsv.gz',\n                           sep='\\t', compression='gzip')\n\nfeatures, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values\n\nclf = make_pipeline(MultiSURF(n_features_to_select=2),\n                    RandomForestClassifier(n_estimators=100))\n\nprint(np.mean(cross_val_score(clf, features, labels)))\n>>> 0.795\n\n\n\n\nMultiSURF*\n\n\n\n\n\n\nParameter\n\n\nValid values\n\n\nEffect\n\n\n\n\n\n\nn_features_to_select\n\n\nAny positive integer\n\n\nThe number of best features to retain after the feature selection process. The \"best\" features are the highest-scored features according to the MultiSURF* scoring process.\n\n\n\n\n\n\ndiscrete_limit\n\n\nAny positive integer\n\n\nValue used to determine if a feature is discrete or continuous. If the number of unique levels in a feature is > discrete_threshold, then it is considered continuous, or discrete otherwise.\n\n\n\n\n\n\nn_jobs\n\n\nAny positive integer or -1\n\n\nThe number cores to dedicate to running the algorithm in parallel with joblib. Set to -1 to use all available cores.\n\n\n\n\n\n\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom skrebate import MultiSURFstar\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\ngenetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'\n                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.tsv.gz',\n                           sep='\\t', compression='gzip')\n\nfeatures, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values\n\nclf = make_pipeline(MultiSURFstar(n_features_to_select=2),\n                    RandomForestClassifier(n_estimators=100))\n\nprint(np.mean(cross_val_score(clf, features, labels)))\n>>> 0.795\n\n\n\n\nTURF\n\n\nTURF advances the feature selection process from a single round to a multi-round process, and can be used in conjunction with any of the Relief-based algorithms. TURF begins with all of the features in the first round, scores them using one of the Relief-based algorithms, then eliminates a portion of them that have the worst scores. With this reduced feature set, TURF again scores the remaining features and eliminates a portion of the worst-scoring features. This process is repeated until a predefined number of features remain.\n\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom skrebate import TuRF\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\ngenetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'\n                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.tsv.gz',\n                           sep='\\t', compression='gzip')\n\nfeatures, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values\nheaders = list(genetic_data.drop(\"class\", axis=1))\n\nclf = make_pipeline(TuRF(core_algorithm=\"MultiSURF\", n_features_to_select=2, step=0.1),\n                    RandomForestClassifier(n_estimators=100))\n\nprint(np.mean(cross_val_score(clf, features, labels, fit_params={'turf__headers': headers})))\n>>> 0.795\n\n\n\n\nAcquiring feature importance scores\n\n\nIn some cases, it may be useful to compute feature importance scores without actually performing feature selection. We have made it possible to access all Relief-based algorithm's scores via the \nfeature_importances_\n attribute. Below is a code example showing how to access the scores from the ReliefF algorithm.\n\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom skrebate import ReliefF\nfrom sklearn.model_selection import train_test_split\n\ngenetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'\n                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.tsv.gz',\n                           sep='\\t', compression='gzip')\n\nfeatures, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values\n\n# Make sure to compute the feature importance scores from only your training set\nX_train, X_test, y_train, y_test = train_test_split(features, labels)\n\nfs = ReliefF()\nfs.fit(X_train, y_train)\n\nfor feature_name, feature_score in zip(genetic_data.drop('class', axis=1).columns,\n                                       fs.feature_importances_):\n    print(feature_name, '\\t', feature_score)\n\n>>>N0    -0.0000166666666667\n>>>N1    -0.006175\n>>>N2    -0.0079\n>>>N3    -0.006275\n>>>N4    -0.00684166666667\n>>>N5    -0.0104416666667\n>>>N6    -0.010275\n>>>N7    -0.00785\n>>>N8    -0.00824166666667\n>>>N9    -0.00515\n>>>N10   -0.000216666666667\n>>>N11   -0.0039\n>>>N12   -0.00291666666667\n>>>N13   -0.00345833333333\n>>>N14   -0.00324166666667\n>>>N15   -0.00886666666667\n>>>N16   -0.00611666666667\n>>>N17   -0.007325\n>>>P1    0.108966666667\n>>>P2    0.111\n\n\n\n\nHigher positive scores indicate that the features are likely predictive of the outcome, whereas negative scores indicate that the features are likely noise. We generally recommend removing all features with negative scores at a minimum.",
            "title": "Using skrebate"
        },
        {
            "location": "/using/#relieff",
            "text": "ReliefF is the most basic of the Relief-based feature selection algorithms, and it requires you to specify the number of nearest neighbors to consider in the scoring algorithm. The parameters for the ReliefF algorithm are as follows:    Parameter  Valid values  Effect    n_features_to_select  Any positive integer or float  The number of best features to retain after the feature selection process. The \"best\" features are the highest-scored features according to the ReliefF scoring process.    n_neighbors  Any positive integer  The number of neighbors to consider when assigning feature importance scores. If a float number is provided, that percentage of training samples is used as the number of neighbors. More neighbors results in more accurate scores, but takes longer.    discrete_limit  Any positive integer  Value used to determine if a feature is discrete or continuous. If the number of unique levels in a feature is > discrete_threshold, then it is considered continuous, or discrete otherwise.    n_jobs  Any positive integer or -1  The number cores to dedicate to running the algorithm in parallel with joblib. Set to -1 to use all available cores.    import pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom skrebate import ReliefF\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\ngenetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'\n                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.tsv.gz',\n                           sep='\\t', compression='gzip')\n\nfeatures, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values\n\nclf = make_pipeline(ReliefF(n_features_to_select=2, n_neighbors=100),\n                    RandomForestClassifier(n_estimators=100))\n\nprint(np.mean(cross_val_score(clf, features, labels)))\n>>> 0.795",
            "title": "ReliefF"
        },
        {
            "location": "/using/#surf",
            "text": "SURF, SURF*, and MultiSURF are all extensions to the ReliefF algorithm that automatically determine the ideal number of neighbors to consider when scoring the features.    Parameter  Valid values  Effect    n_features_to_select  Any positive integer  The number of best features to retain after the feature selection process. The \"best\" features are the highest-scored features according to the SURF scoring process.    discrete_limit  Any positive integer  Value used to determine if a feature is discrete or continuous. If the number of unique levels in a feature is > discrete_threshold, then it is considered continuous, or discrete otherwise.    n_jobs  Any positive integer or -1  The number cores to dedicate to running the algorithm in parallel with joblib. Set to -1 to use all available cores.    import pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom skrebate import SURF\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\ngenetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'\n                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.tsv.gz',\n                           sep='\\t', compression='gzip')\n\nfeatures, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values\n\nclf = make_pipeline(SURF(n_features_to_select=2),\n                    RandomForestClassifier(n_estimators=100))\n\nprint(np.mean(cross_val_score(clf, features, labels)))\n>>> 0.795",
            "title": "SURF"
        },
        {
            "location": "/using/#surf_1",
            "text": "Parameter  Valid values  Effect    n_features_to_select  Any positive integer  The number of best features to retain after the feature selection process. The \"best\" features are the highest-scored features according to the SURF* scoring process.    discrete_limit  Any positive integer  Value used to determine if a feature is discrete or continuous. If the number of unique levels in a feature is > discrete_threshold, then it is considered continuous, or discrete otherwise.    n_jobs  Any positive integer or -1  The number cores to dedicate to running the algorithm in parallel with joblib. Set to -1 to use all available cores.    import pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom skrebate import SURFstar\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\ngenetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'\n                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.tsv.gz',\n                           sep='\\t', compression='gzip')\n\nfeatures, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values\n\nclf = make_pipeline(SURFstar(n_features_to_select=2),\n                    RandomForestClassifier(n_estimators=100))\n\nprint(np.mean(cross_val_score(clf, features, labels)))\n>>> 0.795",
            "title": "SURF*"
        },
        {
            "location": "/using/#multisurf",
            "text": "Parameter  Valid values  Effect    n_features_to_select  Any positive integer  The number of best features to retain after the feature selection process. The \"best\" features are the highest-scored features according to the MultiSURF scoring process.    discrete_limit  Any positive integer  Value used to determine if a feature is discrete or continuous. If the number of unique levels in a feature is > discrete_threshold, then it is considered continuous, or discrete otherwise.    n_jobs  Any positive integer or -1  The number cores to dedicate to running the algorithm in parallel with joblib. Set to -1 to use all available cores.    import pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom skrebate import MultiSURF\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\ngenetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'\n                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.tsv.gz',\n                           sep='\\t', compression='gzip')\n\nfeatures, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values\n\nclf = make_pipeline(MultiSURF(n_features_to_select=2),\n                    RandomForestClassifier(n_estimators=100))\n\nprint(np.mean(cross_val_score(clf, features, labels)))\n>>> 0.795",
            "title": "MultiSURF"
        },
        {
            "location": "/using/#multisurf_1",
            "text": "Parameter  Valid values  Effect    n_features_to_select  Any positive integer  The number of best features to retain after the feature selection process. The \"best\" features are the highest-scored features according to the MultiSURF* scoring process.    discrete_limit  Any positive integer  Value used to determine if a feature is discrete or continuous. If the number of unique levels in a feature is > discrete_threshold, then it is considered continuous, or discrete otherwise.    n_jobs  Any positive integer or -1  The number cores to dedicate to running the algorithm in parallel with joblib. Set to -1 to use all available cores.    import pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom skrebate import MultiSURFstar\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\ngenetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'\n                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.tsv.gz',\n                           sep='\\t', compression='gzip')\n\nfeatures, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values\n\nclf = make_pipeline(MultiSURFstar(n_features_to_select=2),\n                    RandomForestClassifier(n_estimators=100))\n\nprint(np.mean(cross_val_score(clf, features, labels)))\n>>> 0.795",
            "title": "MultiSURF*"
        },
        {
            "location": "/using/#turf",
            "text": "TURF advances the feature selection process from a single round to a multi-round process, and can be used in conjunction with any of the Relief-based algorithms. TURF begins with all of the features in the first round, scores them using one of the Relief-based algorithms, then eliminates a portion of them that have the worst scores. With this reduced feature set, TURF again scores the remaining features and eliminates a portion of the worst-scoring features. This process is repeated until a predefined number of features remain.  import pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom skrebate import TuRF\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\ngenetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'\n                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.tsv.gz',\n                           sep='\\t', compression='gzip')\n\nfeatures, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values\nheaders = list(genetic_data.drop(\"class\", axis=1))\n\nclf = make_pipeline(TuRF(core_algorithm=\"MultiSURF\", n_features_to_select=2, step=0.1),\n                    RandomForestClassifier(n_estimators=100))\n\nprint(np.mean(cross_val_score(clf, features, labels, fit_params={'turf__headers': headers})))\n>>> 0.795",
            "title": "TURF"
        },
        {
            "location": "/using/#acquiring-feature-importance-scores",
            "text": "In some cases, it may be useful to compute feature importance scores without actually performing feature selection. We have made it possible to access all Relief-based algorithm's scores via the  feature_importances_  attribute. Below is a code example showing how to access the scores from the ReliefF algorithm.  import pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom skrebate import ReliefF\nfrom sklearn.model_selection import train_test_split\n\ngenetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'\n                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.tsv.gz',\n                           sep='\\t', compression='gzip')\n\nfeatures, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values\n\n# Make sure to compute the feature importance scores from only your training set\nX_train, X_test, y_train, y_test = train_test_split(features, labels)\n\nfs = ReliefF()\nfs.fit(X_train, y_train)\n\nfor feature_name, feature_score in zip(genetic_data.drop('class', axis=1).columns,\n                                       fs.feature_importances_):\n    print(feature_name, '\\t', feature_score)\n\n>>>N0    -0.0000166666666667\n>>>N1    -0.006175\n>>>N2    -0.0079\n>>>N3    -0.006275\n>>>N4    -0.00684166666667\n>>>N5    -0.0104416666667\n>>>N6    -0.010275\n>>>N7    -0.00785\n>>>N8    -0.00824166666667\n>>>N9    -0.00515\n>>>N10   -0.000216666666667\n>>>N11   -0.0039\n>>>N12   -0.00291666666667\n>>>N13   -0.00345833333333\n>>>N14   -0.00324166666667\n>>>N15   -0.00886666666667\n>>>N16   -0.00611666666667\n>>>N17   -0.007325\n>>>P1    0.108966666667\n>>>P2    0.111  Higher positive scores indicate that the features are likely predictive of the outcome, whereas negative scores indicate that the features are likely noise. We generally recommend removing all features with negative scores at a minimum.",
            "title": "Acquiring feature importance scores"
        },
        {
            "location": "/examples/GAMETES_Example/",
            "text": "Below is a minimal working example in a scikit-learn pipeline with a practice GAMETES genetic analysis data set.\n\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom skrebate import ReliefF\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\ngenetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'\n                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.tsv.gz',\n                           sep='\\t', compression='gzip')\n\nfeatures, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values\n\nclf = make_pipeline(ReliefF(n_features_to_select=2, n_neighbors=100),\n                    RandomForestClassifier(n_estimators=100))\n\nprint(np.mean(cross_val_score(clf, features, labels)))\n\n\n\n\nThis pipeline should achieve an accuracy of about 80%.",
            "title": "GAMETES Example"
        },
        {
            "location": "/contributing/",
            "text": "We welcome you to \ncheck the existing issues\n for bugs or enhancements to work on. If you have an idea for an extension to scikit-rebate, please \nfile a new issue\n so we can discuss it.\n\n\nProject layout\n\n\nThe latest stable release of scikit-rebate is on the \nmaster branch\n, whereas the latest version of scikit-rebate in development is on the \ndevelopment branch\n. Make sure you are looking at and working on the correct branch if you're looking to contribute code.\n\n\nIn terms of directory structure:\n\n\n\n\nAll of scikit-rebate's code sources are in the \nskrebate\n directory\n\n\nThe documentation sources are in the \ndocs_sources\n directory\n\n\nThe latest documentation build is in the \ndocs\n directory\n\n\nUnit tests for scikit-rebate are in the \ntests.py\n file\n\n\n\n\nMake sure to familiarize yourself with the project layout before making any major contributions, and especially make sure to send all code changes to the \ndevelopment\n branch.\n\n\nHow to contribute\n\n\nThe preferred way to contribute to scikit-rebate is to fork the \n\nmain repository\n on\nGitHub:\n\n\n\n\n\n\nFork the \nproject repository\n:\n   click on the 'Fork' button near the top of the page. This creates\n   a copy of the code under your account on the GitHub server.\n\n\n\n\n\n\nClone this copy to your local disk:\n\n\n  $ git clone git@github.com:YourLogin/scikit-rebate.git\n  $ cd scikit-rebate\n\n\n\n\n\n\n\nCreate a branch to hold your changes:\n\n\n  $ git checkout -b my-contribution\n\n\n\n\n\n\n\nMake sure your local environment is setup correctly for development. Installation instructions are almost identical to \nthe user instructions\n except that scikit-rebate should \nnot\n be installed. If you have scikit-rebate installed on your computer, then make sure you are using a virtual environment that does not have scikit-rebate installed. Furthermore, you should make sure you have installed the \nnose\n package into your development environment so that you can test changes locally.\n\n\n  $ conda install nose\n\n\n\n\n\n\n\nStart making changes on your newly created branch, remembering to never work on the \nmaster\n branch! Work on this copy on your computer using Git to do the version control.\n\n\n\n\n\n\nOnce some changes are saved locally, you can use your tweaked version of scikit-rebate by navigating to the project's base directory and running scikit-rebate in a script. You can use an example script in our \nexamples directory\n to begin your testing.\n\n\n\n\n\n\nTo check your changes haven't broken any existing tests and to check new tests you've added pass run the following (note, you must have the \nnose\n package installed within your dev environment for this to work):\n\n\n  $ nosetests -s -v\n\n\n\n\n\n\n\nWhen you're done editing and local testing, run:\n\n\n  $ git add modified_files\n  $ git commit\n\n\n\n\n\n\n\nto record your changes in Git, then push them to GitHub with:\n\n\n      $ git push -u origin my-contribution\n\n\n\nFinally, go to the web page of your fork of the scikit-rebate repo, and click 'Pull Request' (PR) to send your changes to the maintainers for review. Make sure that you send your PR to the \ndevelopment\n branch, as the \nmaster\n branch is reserved for the latest stable release. This will start the CI server to check all the project's unit tests run and send an email to the maintainers.\n\n\n(If any of the above seems like magic to you, then look up the \n\nGit documentation\n on the web.)\n\n\nBefore submitting your pull request\n\n\nBefore you submit a pull request for your contribution, please work through this checklist to make sure that you have done everything necessary so we can efficiently review and accept your changes.\n\n\nIf your contribution changes scikit-rebate in any way:\n\n\n\n\n\n\nUpdate the \ndocumentation\n so all of your changes are reflected there.\n\n\n\n\n\n\nUpdate the \nREADME\n if anything there has changed.\n\n\n\n\n\n\nIf your contribution involves any code changes:\n\n\n\n\n\n\nUpdate the \nproject unit tests\n to test your code changes.\n\n\n\n\n\n\nMake sure that your code is properly commented with \ndocstrings\n and comments explaining your rationale behind non-obvious coding practices.\n\n\n\n\n\n\nIf your contribution requires a new library dependency:\n\n\n\n\n\n\nDouble-check that the new dependency is easy to install via \npip\n or Anaconda and supports both Python 2 and 3. If the dependency requires a complicated installation, then we most likely won't merge your changes because we want to keep scikit-rebate easy to install.\n\n\n\n\n\n\nAdd a line to pip install the library to \n.travis_install.sh\n\n\n\n\n\n\nAdd a line to print the version of the library to \n.travis_install.sh\n\n\n\n\n\n\nSimilarly add a line to print the version of the library to \n.travis_test.sh\n\n\n\n\n\n\nUpdating the documentation\n\n\nWe use \nmkdocs\n to manage our \ndocumentation\n. This allows us to write the docs in Markdown and compile them to HTML as needed. Below are a few useful commands to know when updating the documentation. Make sure that you are running them in the base repository directory.\n\n\n\n\n\n\nmkdocs serve\n: Hosts of a local version of the documentation that you can access at the provided URL. The local version will update automatically as you save changes to the documentation.\n\n\n\n\n\n\nmkdocs build --clean\n: Creates a fresh build of the documentation in HTML. Always run this before deploying the documentation to GitHub.\n\n\n\n\n\n\nmkdocs gh-deploy\n: Deploys the documentation to GitHub. If you're deploying on your fork of scikit-rebate, the online documentation should be accessible at \nhttp://<YOUR GITHUB USERNAME>.github.io/scikit-rebate/\n. Generally, you shouldn't need to run this command because you can view your changes with \nmkdocs serve\n.\n\n\n\n\n\n\nAfter submitting your pull request\n\n\nAfter submitting your pull request, \nTravis-CI\n will automatically run unit tests on your changes and make sure that your updated code builds and runs on Python 2 and 3. We also use services that automatically check code quality and test coverage.\n\n\nCheck back shortly after submitting your pull request to make sure that your code passes these checks. If any of the checks come back with a red X, then do your best to address the errors.",
            "title": "Contributing"
        },
        {
            "location": "/contributing/#project-layout",
            "text": "The latest stable release of scikit-rebate is on the  master branch , whereas the latest version of scikit-rebate in development is on the  development branch . Make sure you are looking at and working on the correct branch if you're looking to contribute code.  In terms of directory structure:   All of scikit-rebate's code sources are in the  skrebate  directory  The documentation sources are in the  docs_sources  directory  The latest documentation build is in the  docs  directory  Unit tests for scikit-rebate are in the  tests.py  file   Make sure to familiarize yourself with the project layout before making any major contributions, and especially make sure to send all code changes to the  development  branch.",
            "title": "Project layout"
        },
        {
            "location": "/contributing/#how-to-contribute",
            "text": "The preferred way to contribute to scikit-rebate is to fork the  main repository  on\nGitHub:    Fork the  project repository :\n   click on the 'Fork' button near the top of the page. This creates\n   a copy of the code under your account on the GitHub server.    Clone this copy to your local disk:    $ git clone git@github.com:YourLogin/scikit-rebate.git\n  $ cd scikit-rebate    Create a branch to hold your changes:    $ git checkout -b my-contribution    Make sure your local environment is setup correctly for development. Installation instructions are almost identical to  the user instructions  except that scikit-rebate should  not  be installed. If you have scikit-rebate installed on your computer, then make sure you are using a virtual environment that does not have scikit-rebate installed. Furthermore, you should make sure you have installed the  nose  package into your development environment so that you can test changes locally.    $ conda install nose    Start making changes on your newly created branch, remembering to never work on the  master  branch! Work on this copy on your computer using Git to do the version control.    Once some changes are saved locally, you can use your tweaked version of scikit-rebate by navigating to the project's base directory and running scikit-rebate in a script. You can use an example script in our  examples directory  to begin your testing.    To check your changes haven't broken any existing tests and to check new tests you've added pass run the following (note, you must have the  nose  package installed within your dev environment for this to work):    $ nosetests -s -v    When you're done editing and local testing, run:    $ git add modified_files\n  $ git commit    to record your changes in Git, then push them to GitHub with:        $ git push -u origin my-contribution  Finally, go to the web page of your fork of the scikit-rebate repo, and click 'Pull Request' (PR) to send your changes to the maintainers for review. Make sure that you send your PR to the  development  branch, as the  master  branch is reserved for the latest stable release. This will start the CI server to check all the project's unit tests run and send an email to the maintainers.  (If any of the above seems like magic to you, then look up the  Git documentation  on the web.)",
            "title": "How to contribute"
        },
        {
            "location": "/contributing/#before-submitting-your-pull-request",
            "text": "Before you submit a pull request for your contribution, please work through this checklist to make sure that you have done everything necessary so we can efficiently review and accept your changes.  If your contribution changes scikit-rebate in any way:    Update the  documentation  so all of your changes are reflected there.    Update the  README  if anything there has changed.    If your contribution involves any code changes:    Update the  project unit tests  to test your code changes.    Make sure that your code is properly commented with  docstrings  and comments explaining your rationale behind non-obvious coding practices.    If your contribution requires a new library dependency:    Double-check that the new dependency is easy to install via  pip  or Anaconda and supports both Python 2 and 3. If the dependency requires a complicated installation, then we most likely won't merge your changes because we want to keep scikit-rebate easy to install.    Add a line to pip install the library to  .travis_install.sh    Add a line to print the version of the library to  .travis_install.sh    Similarly add a line to print the version of the library to  .travis_test.sh",
            "title": "Before submitting your pull request"
        },
        {
            "location": "/contributing/#updating-the-documentation",
            "text": "We use  mkdocs  to manage our  documentation . This allows us to write the docs in Markdown and compile them to HTML as needed. Below are a few useful commands to know when updating the documentation. Make sure that you are running them in the base repository directory.    mkdocs serve : Hosts of a local version of the documentation that you can access at the provided URL. The local version will update automatically as you save changes to the documentation.    mkdocs build --clean : Creates a fresh build of the documentation in HTML. Always run this before deploying the documentation to GitHub.    mkdocs gh-deploy : Deploys the documentation to GitHub. If you're deploying on your fork of scikit-rebate, the online documentation should be accessible at  http://<YOUR GITHUB USERNAME>.github.io/scikit-rebate/ . Generally, you shouldn't need to run this command because you can view your changes with  mkdocs serve .",
            "title": "Updating the documentation"
        },
        {
            "location": "/contributing/#after-submitting-your-pull-request",
            "text": "After submitting your pull request,  Travis-CI  will automatically run unit tests on your changes and make sure that your updated code builds and runs on Python 2 and 3. We also use services that automatically check code quality and test coverage.  Check back shortly after submitting your pull request to make sure that your code passes these checks. If any of the checks come back with a red X, then do your best to address the errors.",
            "title": "After submitting your pull request"
        },
        {
            "location": "/releases/",
            "text": "scikit-rebate 0.5\n\n\n\n\n\n\nAdded fixes to score normalizations that should ensure that feature scores for all algorithms fall between -1 and 1. \n\n\n\n\n\n\nAdded multi-class endpoint functionality. (now discriminates between binary and multiclass endpoints) Includes new methods for multi-class score update normalization.\n\n\n\n\n\n\nFixed normalization for missing data.\n\n\n\n\n\n\nFixed inconsistent pre-normalization for continuous feature data. \n\n\n\n\n\n\nAdded a custom ramp function to improve performance of all algorithms on data with a mix of discrete and continuous features.  Based on the standard deviation of a given continuous feature. \n\n\n\n\n\n\nUpdated the implementation of TuRF as an internal custom component of ReBATE.\n\n\n\n\n\n\nscikit-rebate 0.4\n\n\n\n\n\n\nAdded support for multicore processing to all Relief algorithms. Multiprocessing is now also supported in Python 2.\n\n\n\n\n\n\nThe \nReliefF\n algorithm now accepts float values in the range (0, 1.0] for the \nn_neighbors\n parameter. Float values will be interpreted as a fraction of the training set sample size.\n\n\n\n\n\n\nRefined the MultiSURF and MultiSURF* algorithms. From our internal research, MultiSURF is now one of our best-performing feature selection algorithms.\n\n\n\n\n\n\nscikit-rebate 0.3\n\n\n\n\n\n\nAdded a parallelization parameter, \nn_jobs\n, to ReliefF, SURF, SURF*, and MultiSURF via joblib.\n\n\n\n\n\n\nRenamed the \ndlimit\n parameter to \ndiscrete_limit\n to better reflect the purpose of the parameter.\n\n\n\n\n\n\nMinor code optimizations.\n\n\n\n\n\n\nscikit-rebate 0.2\n\n\n\n\n\n\nAdded documentation.\n\n\n\n\n\n\nMinor code optimizations.\n\n\n\n\n\n\nscikit-rebate 0.1\n\n\n\n\nInitial release of Relief algorithms, including ReliefF, SURF, SURF*, and MultiSURF.",
            "title": "Release Notes"
        },
        {
            "location": "/releases/#scikit-rebate-05",
            "text": "Added fixes to score normalizations that should ensure that feature scores for all algorithms fall between -1 and 1.     Added multi-class endpoint functionality. (now discriminates between binary and multiclass endpoints) Includes new methods for multi-class score update normalization.    Fixed normalization for missing data.    Fixed inconsistent pre-normalization for continuous feature data.     Added a custom ramp function to improve performance of all algorithms on data with a mix of discrete and continuous features.  Based on the standard deviation of a given continuous feature.     Updated the implementation of TuRF as an internal custom component of ReBATE.",
            "title": "scikit-rebate 0.5"
        },
        {
            "location": "/releases/#scikit-rebate-04",
            "text": "Added support for multicore processing to all Relief algorithms. Multiprocessing is now also supported in Python 2.    The  ReliefF  algorithm now accepts float values in the range (0, 1.0] for the  n_neighbors  parameter. Float values will be interpreted as a fraction of the training set sample size.    Refined the MultiSURF and MultiSURF* algorithms. From our internal research, MultiSURF is now one of our best-performing feature selection algorithms.",
            "title": "scikit-rebate 0.4"
        },
        {
            "location": "/releases/#scikit-rebate-03",
            "text": "Added a parallelization parameter,  n_jobs , to ReliefF, SURF, SURF*, and MultiSURF via joblib.    Renamed the  dlimit  parameter to  discrete_limit  to better reflect the purpose of the parameter.    Minor code optimizations.",
            "title": "scikit-rebate 0.3"
        },
        {
            "location": "/releases/#scikit-rebate-02",
            "text": "Added documentation.    Minor code optimizations.",
            "title": "scikit-rebate 0.2"
        },
        {
            "location": "/releases/#scikit-rebate-01",
            "text": "Initial release of Relief algorithms, including ReliefF, SURF, SURF*, and MultiSURF.",
            "title": "scikit-rebate 0.1"
        },
        {
            "location": "/citing/",
            "text": "If you use scikit-rebate or the MultiSURF algorithm in a scientific publication, please consider citing the following paper (currently available as a pre-print in arXiv):\n\n\nUrbanowicz, Ryan J., Randal S. Olson, Peter Schmitt, Melissa Meeker, and Jason H. Moore. \"Benchmarking relief-based feature selection methods.\" arXiv preprint arXiv:1711.08477 (2017).\n\n\nAlternatively a complete review of Relief-based algorithms is available at:\n\n\nUrbanowicz, Ryan J., Melissa Meeker, William LaCava, Randal S. Olson, and Jason H. Moore. \"Relief-based feature selection: introduction and review.\" arXiv preprint arXiv:1711.08421 (2017).\n\n\nTo cite the original Relief paper:\n\n\nKira, Kenji, and Larry A. Rendell. \"A practical approach to feature selection.\" In Machine Learning Proceedings 1992, pp. 249-256. 1992.\n\n\nTo cite the original ReliefF paper: \n\n\nKononenko, Igor. \"Estimating attributes: analysis and extensions of RELIEF.\" In European conference on machine learning, pp. 171-182. Springer, Berlin, Heidelberg, 1994.\n\n\nTo cite the original SURF paper:\n\n\nGreene, Casey S., Nadia M. Penrod, Jeff Kiralis, and Jason H. Moore. \"Spatially uniform relieff (SURF) for computationally-efficient filtering of gene-gene interactions.\" BioData mining 2, no. 1 (2009): 5.\n\n\nTo cite the original SURF* paper: \n\n\nGreene, Casey S., Daniel S. Himmelstein, Jeff Kiralis, and Jason H. Moore. \"The informative extremes: using both nearest and farthest individuals can improve relief algorithms in the domain of human genetics.\" In European Conference on Evolutionary Computation, Machine Learning and Data Mining in Bioinformatics, pp. 182-193. Springer, Berlin, Heidelberg, 2010.\n\n\nTo cite the original MultiSURF* paper:\n\n\nGranizo-Mackenzie, Delaney, and Jason H. Moore. \"Multiple threshold spatially uniform relieff for the genetic analysis of complex human diseases.\" In European Conference on Evolutionary Computation, Machine Learning and Data Mining in Bioinformatics, pp. 1-10. Springer, Berlin, Heidelberg, 2013.\n\n\nTo cite the original TuRF paper: \n\n\nMoore, Jason H., and Bill C. White. \"Tuning ReliefF for genome-wide genetic analysis.\" In European Conference on Evolutionary Computation, Machine Learning and Data Mining in Bioinformatics, pp. 166-175. Springer, Berlin, Heidelberg, 2007.",
            "title": "Citing"
        },
        {
            "location": "/support/",
            "text": "scikit-rebate was developed in the \nComputational Genetics Lab\n with funding from the \nNIH\n. We are incredibly grateful for their support during the development of this project.",
            "title": "Support"
        }
    ]
}